RESULTS FOR : epoch = 1, batch = 128, freeze =26, lr = 0.001
train-acc
[0.037359900373599]
------------------------------
test-acc
[0.017766497461928935]
------------------------------
train-acc5
[0.21357409713574096]
------------------------------
test-loss
[2.9981009790740036]
------------------------------
train-loss
[2.998311617306131]
------------------------------
test-acc5
[0.22588832487309646]
------------------------------


RESULTS FOR : epoch = 3, batch = 128, freeze =26, lr = 0.001
test-loss
[2.9957163830093925, 2.9959926823068996, 2.9959752620174194]
------------------------------
test-acc
[0.050761421319796954, 0.04568527918781726, 0.04314720812182741]
------------------------------
test-acc5
[0.2639593908629442, 0.2766497461928934, 0.2817258883248731]
------------------------------
train-acc
[0.040473225404732256, 0.04420921544209216, 0.045454545454545456]
------------------------------
train-acc5
[0.2266500622665006, 0.23661270236612703, 0.24221668742216687]
------------------------------
train-loss
[2.997470655595677, 2.996765473711387, 2.996536934806282]
------------------------------


RESULTS FOR : epoch = 5, batch = 128, freeze =26, lr = 0.001
train-acc5
[0.23723536737235368, 0.23848069738480698, 0.22851805728518057, 0.24470734744707348, 0.23225404732254049]
------------------------------
test-acc5
[0.25888324873096447, 0.23604060913705585, 0.23096446700507614, 0.23857868020304568, 0.23604060913705585]
------------------------------
test-loss
[2.995928252408952, 2.995427937677064, 2.9953224186969893, 2.9952132835000906, 2.9952728833038793]
------------------------------
test-acc
[0.048223350253807105, 0.048223350253807105, 0.050761421319796954, 0.050761421319796954, 0.050761421319796954]
------------------------------
train-acc
[0.0460772104607721, 0.05105853051058531, 0.0448318804483188, 0.047322540473225407, 0.053549190535491904]
------------------------------
train-loss
[2.99768221274408, 2.997484942302015, 2.998069875118593, 2.997417964495876, 2.99690128471308]
------------------------------


RESULTS FOR : epoch = 10, batch = 128, freeze =26, lr = 0.001
test-acc5
[0.22588832487309646, 0.2182741116751269, 0.2182741116751269, 0.2182741116751269, 0.23096446700507614, 0.22588832487309646, 0.2233502538071066, 0.23096446700507614, 0.22588832487309646, 0.22842639593908629]
------------------------------
train-acc
[0.051681195516811954, 0.0547945205479452, 0.05105853051058531, 0.051681195516811954, 0.051681195516811954, 0.050435865504358655, 0.046699875466998754, 0.046699875466998754, 0.049813200498132, 0.050435865504358655]
------------------------------
test-acc
[0.048223350253807105, 0.04060913705583756, 0.04060913705583756, 0.04060913705583756, 0.04060913705583756, 0.04060913705583756, 0.04060913705583756, 0.04314720812182741, 0.04060913705583756, 0.04060913705583756]
------------------------------
train-loss
[2.997711611269123, 2.997422085604068, 2.997861927502776, 2.9980888138078665, 2.997969267525679, 2.9975057996224943, 2.997945636473735, 2.9974286321685146, 2.9978104994573154, 2.9980864340757227]
------------------------------
train-acc5
[0.24097135740971357, 0.24097135740971357, 0.2465753424657534, 0.23536737235367372, 0.23972602739726026, 0.24533001245330013, 0.24719800747198006, 0.24159402241594022, 0.23474470734744707, 0.23661270236612703]
------------------------------
test-loss
[2.9996575135264907, 2.999284705534804, 2.999245978854029, 2.9992162249415055, 2.99923892795737, 2.999239824750097, 2.9991641649739997, 2.999275070761666, 2.999212281958101, 2.9991987090425445]
------------------------------
